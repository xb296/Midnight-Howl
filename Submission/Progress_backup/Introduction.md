# Introduction

[TOC]

The origin of languages is a hot topic for decades. Some argue languages emerged from imitating natural sounds, while others argue languages emerged from referential to objects. The rise of machine learning provides new opportunities to study this topic in simulated environments. In this project, we developed agents powered by deep reinforcement learning algorithms to investigate the problem called emergent communication. In this setting, two agents interact with each other to cooperatively solve a task by developing a communication protocol. We successfully trained agents to play referential games, and confirmed the language protocol share some common properties of human languages, for example, possess grammatical structures.

## Reaearch Aims

.

## Contribution

I contributed to the research field by examining how different environments can lead to emergence of languages. Through my experimentation, reinforcement learning agents can successfully establish a communication protocol to communicate the message to complete the tasks. (H1) By using simple Q-Learning and policy gradient methods, I confirmed that agetns can establish communication protocols in both simple and complex referential games. (H2)

Through computing the cosine similarity of the target space and the message space, I observed that the emerged language shows signs of compositionality, which is a core property of grammatical structures. 

- A set of referential game environments with different complexity, controlled by parameters
- (Detailed analysis of environmental complexity)
- Successful agents
- Formalised analysis of the language structures

In Chapter 1, we presents

